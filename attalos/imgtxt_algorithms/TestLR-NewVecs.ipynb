{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Linear Regression\n",
    "\n",
    "This notebook is an example that will test the generalization capability of a regression to word vectors. There are three corpora involved.\n",
    "\n",
    "## Required Data\n",
    "\n",
    "1. The _word vector corpora_\n",
    "  * Examples: New York Times, Wikipedia Text8\n",
    "  * Data: Pretrained word vectors (word2vec, etc.)\n",
    "2. The _training corpora_\n",
    "  * Examples: IAPR-TC12, MSCOCO, Visual Genome\n",
    "  * Data:\n",
    "    - Training image features and text labels\n",
    "    - Testing image features and text labels <-- Used as validation data\n",
    "3. A _testing corpora_ with a different vocabulary\n",
    "  * Examples: MSCOCO, Visual Genome, etc.\n",
    "  * Data: Training and testing image features\n",
    "\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import sys\n",
    "\n",
    "## Should probably update to PYTHONPATH\n",
    "sys.path.append('/data/fs4/home/kni/attalos/')\n",
    "# ls /data/fs4/home/kni/attalos/\n",
    "\n",
    "## Import word vector load in\n",
    "import attalos.imgtxt_algorithms.util.readw2v as rw2v\n",
    "\n",
    "## Import linear regression\n",
    "import attalos.imgtxt_algorithms.linearregression.LinearRegression as linreg\n",
    "\n",
    "## Import evaluation code (right now, using Octave soft evaluation)\n",
    "# from attalos.evaluation.evaluation import Eval\n",
    "from oct2py import octave\n",
    "octave.addpath('../evaluation/')\n",
    "\n",
    "reload(linreg)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the word vectors in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "def save_centroids(centroids, target_path):\n",
    "    with open(target_path, \"wb\") as f:\n",
    "        pickle.dump(centroids, f)\n",
    "\n",
    "def load_centroids(target_path):\n",
    "    with open(target_path, \"rb\") as f:\n",
    "        centroids = pickle.load(f)\n",
    "    return centroids\n",
    "\n",
    "def compute_centroid_projection(basis, v):\n",
    "    projection = []\n",
    "    for dim in xrange(0, len(basis.keys())):\n",
    "        if dim not in basis:\n",
    "            projection.append(0)\n",
    "            continue\n",
    "        similarity = np.dot(v, basis[dim])\n",
    "        similarity = expit(10*similarity)\n",
    "        projection.append(similarity)\n",
    "    return np.asarray(projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centroids = load_centroids('/data/fs4/teams/attalos/wordvecs/centroids_kmeans500skipg.pkl')\n",
    "F = rw2v.ReadW2V('/data/fs4/teams/attalos/wordvecs/text9Bvin.bin')\n",
    "vectors = F.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hellocentroid = compute_centroid_projection( centroids, vectors['television'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training corpora in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.load('linearregression/data/iaprtc_alexfc7.npz')\n",
    "D = open('linearregression/data/iaprtc_dictionary.txt').read().splitlines()\n",
    "train_ims = [ im.split('/')[-1] for im in open('linearregression/data/iaprtc_trainlist.txt').read().splitlines() ]\n",
    "xTr = data['xTr'].T\n",
    "yTr = data['yTr'].T\n",
    "xTe = data['xTe'].T\n",
    "yTe = data['yTe'].T\n",
    "\n",
    "test_ims_full = [ im for im in open('linearregression/data/iaprtc_testlist.txt').read().splitlines() ]\n",
    "train_ims_full = [ im for im in open('linearregression/data/iaprtc_trainlist.txt').read().splitlines() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag list for image 2868 is empty!\n"
     ]
    }
   ],
   "source": [
    "newvecs = np.zeros((len(yTr),500))\n",
    "for m in xrange( 0, len(yTr) ):\n",
    "    tags = [ D[ i ] for i in np.where( yTr[m] > 0.5 )[0] ]\n",
    "    taglist = [vectors[ tag ] for tag in tags if tag not in ['tee-shirt', 'bedcover', 'table-cloth'] ]\n",
    "    if taglist:\n",
    "        tagvecs = np.array( [compute_centroid_projection(centroids, tag) for tag in taglist] )\n",
    "        newvecs[m] = tagvecs.mean( axis=0 )\n",
    "    else:\n",
    "        print \"tag list for image \"+str(m)+\" is empty!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelvecs = np.zeros( (len(D), 500) )\n",
    "for i in range(len(D)):\n",
    "    if D[i] not in ['tee-shirt', 'bedcover', 'table-cloth']:\n",
    "        vec2save = compute_centroid_projection(centroids, vectors[D[i]])\n",
    "        labelvecs[i] = vec2save / np.linalg.norm(vec2save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load testing corpora in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print np.isnan(labelvecs).any()\n",
    "print np.isnan(newvecs).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building W matrix = Y \\ X = Y^T X (X X^T)^-1\n"
     ]
    }
   ],
   "source": [
    "mp_solution = linreg.LinearRegression(normX = True)\n",
    "mp_solution.train(xTr, newvecs)\n",
    "yHat = mp_solution.predict(xTe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FinalVal = yHat.dot(labelvecs.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0940166343386\n",
      "0.0513964161015\n",
      "0.0664605830674\n"
     ]
    }
   ],
   "source": [
    "[precision, recall, f1score] = octave.evaluate(yTe.T, FinalVal.T, 5)\n",
    "print precision\n",
    "print recall\n",
    "print f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Randomly select an image\n",
    "i=np.random.randint(0, yTe.shape[1])\n",
    "\n",
    "# Run example\n",
    "imname='linearregression/images/'+test_ims_full[i]+'.jpg';\n",
    "print \"Looking at the \"+str(i)+\"th image: \"+imname\n",
    "im=plt.imread(imname)\n",
    "\n",
    "# Prediction\n",
    "ypwords = [D[j] for j in yHat[i].argsort()[::-1] [ 0:(yHat[i]>0.2).sum() ] ]\n",
    "# Truth\n",
    "ytwords = [D[j] for j in np.where(yTe[i] > 0.5)[0] ]\n",
    "\n",
    "plt.imshow(im)\n",
    "print 'Predicted: '+ ', '.join(ypwords)\n",
    "print 'Truth:     '+ ', '.join(ytwords)\n",
    "\n",
    "plt.figure()\n",
    "plt.stem( yHat[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attalos-2.7",
   "language": "python",
   "name": "attalos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
