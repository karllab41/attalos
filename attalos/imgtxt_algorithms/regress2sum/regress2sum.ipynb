{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from enum import Enum\n",
    "import gzip\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import dok_matrix, csr_matrix\n",
    "import tensorflow as tf\n",
    "\n",
    "# Attalos Imports\n",
    "import sys\n",
    "sys.path.append('/home/kni/local-kni/_update_negsamp/kyle_update/')\n",
    "import attalos.util.log.log as l\n",
    "from attalos.dataset.dataset import Dataset\n",
    "from attalos.evaluation.evaluation import Evaluation\n",
    "\n",
    "# Local models\n",
    "from mse import MSEModel\n",
    "from negsampling import NegSamplingModel\n",
    "from fast0tag import FastZeroTagModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup global objects\n",
    "logger = l.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from attalos.imgtxt_algorithms.regress2sum.multihot import MultihotModel\n",
    "from attalos.imgtxt_algorithms.regress2sum.naivesum import NaiveSumModel\n",
    "from attalos.imgtxt_algorithms.regress2sum.wdv import WDVModel\n",
    "# reload(attalos.imgtxt_algorithms.regress2sum.negsampling)\n",
    "from attalos.imgtxt_algorithms.regress2sum.negsampling import NegSamplingModel\n",
    "from attalos.dataset.wordvectors.glove import GloveWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Temp object using duck typing to replace command line arguments\n",
    "args = lambda: None\n",
    "#args.image_feature_file_train = \"/local_data/teams/attalos/features/image/espgame_train_20160823_inception.hdf5\"\n",
    "#args.text_feature_file_train = \"/local_data/teams/attalos/features/text/espgame_train_20160823_text.json.gz\"\n",
    "#args.image_feature_file_test = \"/local_data/teams/attalos/features/image/espgame_test_20160823_inception.hdf5\"\n",
    "#args.text_feature_file_test = \"/local_data/teams/attalos/features/text/espgame_test_20160823_text.json.gz\"\n",
    "args.image_feature_file_train = \"/local_data/teams/attalos/features/image/iaprtc_train_20160816_inception.hdf5\"\n",
    "args.text_feature_file_train = \"/local_data/teams/attalos/features/text/iaprtc_train_20160816_text.json.gz\"\n",
    "args.image_feature_file_test = \"/local_data/teams/attalos/features/image/iaprtc_test_20160816_inception.hdf5\"\n",
    "args.text_feature_file_test = \"/local_data/teams/attalos/features/text/iaprtc_test_20160816_text.json.gz\"\n",
    "args.word_vector_file = \"/local_data/kylez/glove.6B.200d.txt\"\n",
    "args.word_vector_type = \"glove\"\n",
    "args.model_type = \"negsamp\"\n",
    "args.cross_eval = False\n",
    "args.in_memory = True\n",
    "args.model_input_path = None\n",
    "args.model_output_path = None\n",
    "args.num_epochs = 400\n",
    "args.batch_size = 100\n",
    "args.learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WordVectorTypes(Enum):\n",
    "    w2v = 1\n",
    "    glove = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ModelTypes(Enum):\n",
    "    mse = 1\n",
    "    negsampling = 2\n",
    "    fast0tag = 3\n",
    "    multihot = MultihotModel\n",
    "    naivesum = NaiveSumModel\n",
    "    wdv = WDVModel\n",
    "    negsamp = NegSamplingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_batch(sess, model, batch):\n",
    "    train_x, train_y = batch\n",
    "    training_loss = model.fit(sess, train_x, train_y)\n",
    "    return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(sess, model, train_dataset, batch_size):\n",
    "    training_losses = []\n",
    "    for cur_batch_num, batch in enumerate(model.to_batches(train_dataset, batch_size)):\n",
    "        training_loss = train_batch(sess, model, batch)\n",
    "        training_losses.append(training_loss)\n",
    "    avg_training_loss = sum(training_losses) / float(len(training_losses))\n",
    "    return avg_training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(sess, model, num_epochs, train_dataset, batch_size, epoch_verbosity_rate=10):\n",
    "    for cur_epoch in xrange(num_epochs):\n",
    "        verbose = cur_epoch % epoch_verbosity_rate == 0\n",
    "        avg_training_loss = train_epoch(sess, model, train_dataset, batch_size)\n",
    "        if verbose:\n",
    "            logger.info(\"Finished epoch %s. (Avg. training loss: %s)\" % (cur_epoch, avg_training_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_wv_model(word_vector_file, word_vector_type):\n",
    "    if args.word_vector_type == WordVectorTypes.glove.name:\n",
    "        from glove import Glove\n",
    "        glove_model = Glove.load_stanford(word_vector_file)\n",
    "        wv_model = GloveWrapper(glove_model)\n",
    "    else: #args.word_vector_type == WordVectorTypes.w2v.name:\n",
    "        import word2vec\n",
    "        w2v_model = word2vec.load(word_vector_file)\n",
    "        wv_model = W2VWrapper(w2v_model)\n",
    "    return wv_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-09-09 23:21:47,660] [INFO] Parsing train and test datasets.\n",
      "[2016-09-09 23:21:47,959] [INFO] Reading word vectors from file.\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Parsing train and test datasets.\")\n",
    "train_dataset = Dataset(args.image_feature_file_train, args.text_feature_file_train, load_image_feats_in_mem=args.in_memory)\n",
    "test_dataset = Dataset(args.image_feature_file_test, args.text_feature_file_test)\n",
    "\n",
    "logger.info(\"Reading word vectors from file.\")\n",
    "# wv_model = load_wv_model(args.word_vector_file, args.word_vector_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import attalos.imgtxt_algorithms.util.readw2v as readw2v\n",
    "from attalos.imgtxt_algorithms.util.readw2v import initVo, readvocab\n",
    "# Word Vectors\n",
    "w2vfile = readw2v.ReadW2V('/local_data/kni/data/vectors-phrase.bin')\n",
    "w2v_model = w2vfile.readlines(100000)\n",
    "# Require rescale of word vectors to avoid NaNs\n",
    "for word in w2v_model.keys():\n",
    "    w2v_model[word] *= 1.0\n",
    "    w2v_model[word] = w2v_model[word].astype(np.float32)\n",
    "Wd, Id = readvocab('/local_data/kni/data/vectors-phrase.vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sess.close()\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(w2v_model['hello'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-09-09 23:22:07,465] [INFO] Selecting model class: NegSamplingModel\n",
      "[2016-09-09 23:22:09,915] [INFO] Tensor(\"fully_connected_1/BiasAdd:0\", shape=(?, 200), dtype=float32)\n",
      "[2016-09-09 23:22:09,916] [INFO] Tensor(\"transpose:0\", shape=(?, ?, ?), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"fully_connected_1/BiasAdd:0\", shape=(?, 200), dtype=float32)\n",
      "Tensor(\"transpose:0\", shape=(?, ?, ?), dtype=float64)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor conversion requested dtype float32 for Tensor with dtype float64: 'Tensor(\"transpose:0\", shape=(?, ?, ?), dtype=float64)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-ab6dc23a6de5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Selecting model class: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmodel_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#datasets = [train_dataset] if args.cross_eval else [train_dataset, test_dataset]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_cls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mvars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kni/local-kni/_update_negsamp/kyle_update/attalos/imgtxt_algorithms/regress2sum/negsampling.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, w2v_model, train_dataset, test_dataset, learning_rate, hidden_units, optim_words, use_batch_norm, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtruth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction_indices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduction_indicies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mpos_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeanlogsig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prediction'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pos_vecs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[0mneg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeanlogsig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prediction'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'neg_vecs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mneg_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kni/local-kni/_update_negsamp/kyle_update/attalos/imgtxt_algorithms/regress2sum/negsampling.pyc\u001b[0m in \u001b[0;36mmeanlogsig\u001b[1;34m(pred, truth)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[0mtruth\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtruth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction_indices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduction_indicies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mpos_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeanlogsig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prediction'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pos_vecs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    751\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    619\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconversion_func\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfuncs_at_priority\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m           \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[1;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    562\u001b[0m     raise ValueError(\n\u001b[0;32m    563\u001b[0m         \u001b[1;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m         % (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[0;32m    565\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor conversion requested dtype float32 for Tensor with dtype float64: 'Tensor(\"transpose:0\", shape=(?, ?, ?), dtype=float64)'"
     ]
    }
   ],
   "source": [
    "model_cls = ModelTypes[args.model_type].value\n",
    "logger.info(\"Selecting model class: %s\" % model_cls.__name__)\n",
    "#datasets = [train_dataset] if args.cross_eval else [train_dataset, test_dataset]\n",
    "model = model_cls(w2v_model, train_dataset=train_dataset, test_dataset=test_dataset, **vars(args))\n",
    "model.initialize_model(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.info(\"Starting training phase.\")\n",
    "train(sess, model, args.num_epochs, train_dataset, args.batch_size) #, train_dataset, wv_model, test_dataset=test_dataset, epoch_verbosity_rate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logger.info(\"Starting evaluation phase.\")\n",
    "test_x, test_y = model.to_ndarrs(test_dataset)\n",
    "predictions = model.predict(sess, test_x)\n",
    "evaluator = Evaluation(test_y, predictions, k=5)\n",
    "logger.info(\"Evaluation (precision, recall, f1): %s\" % evaluator.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
