{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import scipy.sparse as sprs\n",
    "import sys\n",
    "import shutil\n",
    "import os\n",
    "import tarfile\n",
    "import argparse\n",
    "import gzip\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "# Evaluation imports\n",
    "from oct2py import octave\n",
    "octave.addpath('../../evaluation/')\n",
    "\n",
    "# Python 2 - 3 imports\n",
    "import six\n",
    "\n",
    "# Tensorflow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn as learn\n",
    "from tensorflow.contrib import layers \n",
    "import tflearn\n",
    "\n",
    "# Attalos specific imports\n",
    "sys.path.append('/home/kni/local-kni/attalos')\n",
    "from setops import replaceword, union, difference, intersection\n",
    "from load_entire_dataset import load_entire_dataset, load_entire_dataset_di\n",
    "import attalos.imgtxt_algorithms.util.readw2v as readw2v\n",
    "from attalos.imgtxt_algorithms.util.readw2v import initVo, readvocab\n",
    "from attalos.evaluation.evaluation import Evaluation\n",
    "from models import imageWmodel, updateVoX, updateVoSum, get_batch, get_batch_image\n",
    "from models import adaptWords, costYViVo\n",
    "\n",
    "# Display\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Definitions\n",
    "1. `epochs` = number of epochs\n",
    "2. `bsize` = batch size\n",
    "3. `updateVo` = None/updateVoSum/updateVoX <- types of update\n",
    "4. `nsampims` = None/negativeims <-- sample from independent words / words from one image\n",
    "5. `initWVVo` = True/False  <-- initialize Vo with word vectors or randomly\n",
    "6. `learnrate` = learning rate\n",
    "7. `datadir` = path to data directory. Need to replace: `<PATH-TO_DATASETS>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "bsize = 1024\n",
    "updateVo =  'updateVoX' # 'updateVoSum' # None/'updateVoSum/updateVoX'\n",
    "nsampims = None #'negativeims'\n",
    "initWVVo = True\n",
    "learnrate=0.1\n",
    "minlearnrate = 1.0e-6\n",
    "wweight = 0.3\n",
    "hidden_units=[2048, 1024,200]\n",
    "datadir='/data/fs4/teams/attalos/features/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the *image* dataset\n",
    "\n",
    "#### Load datasets  \n",
    "The function `load_entire_dataset` will load an entire dataset in. Here,\n",
    "- `dataset` can be `yfcc`, `iaprtc12`, or `espgame`  \n",
    "- `split` can be `train` or `test`\n",
    "\n",
    "#### The data that has been loaded in\n",
    "- `x**`, image features\n",
    "  - `xTr`, training features\n",
    "  - `xTe`, testing features\n",
    "  - `xVa`, validation features\n",
    "- `y**`, labels\n",
    "- `d**`, dictionary of word labels\n",
    "- `****list`, list of images originally being used\n",
    "- `trHot` is used as a one hot encoding object so that the validation has the same hot encoding\n",
    "\n",
    "#### You need to fill in `datadir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xTr, yTr, dTr, trainlist, dirTr, trHot = load_entire_dataset_di('iaprtc12', datadir=datadir, split='train')\n",
    "xVa, yVa, dVa, validlist, dirVa, _ = load_entire_dataset_di('iaprtc12', datadir=datadir, split='test', allhot=trHot)\n",
    "xTe, yTe, dTe, _, testlist, dirTe = load_entire_dataset_di('espgame', datadir=datadir, split='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read vocabulary form word2vec file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2vfile = readw2v.ReadW2V('/local_data/kni/data/vectors-phrase.bin')\n",
    "wordvecs = w2vfile.readlines(100000)\n",
    "# Require rescale of word vectors to avoid NaNs\n",
    "for word in wordvecs.keys():\n",
    "    wordvecs[word] *= 0.1\n",
    "Wd, Id = readvocab('/local_data/kni/data/vectors-phrase.vocab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Joint Vocabulary and Custom Set Operations\n",
    "\n",
    "Recall that the dictionary between training and testing is different. The set operations that I have implemented below \n",
    "- `VoU` is the union of word vectors in both training and test set\n",
    "- `VoD` is the set difference between test set and training set\n",
    "\n",
    "Additionally, you will notice that I have only used the first one hundred thousand words above. Apparently, there are some words the image corpus labels that aren't actually in the word vectors, which can be remedied by replacing your dictionary with equivalent words. The below are words that are replaced with those found in word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace words in the dictionary that aren't in word2vec space\n",
    "replaceword(dTr, 'bedcover', 'bedding')\n",
    "replaceword(dTr, 'tussock', 'turf')\n",
    "replaceword(dTr, 'tee-shirt', 'shirts')\n",
    "replaceword(dTr, 'table-cloth', 'tablecloth')\n",
    "replaceword(dTr, 'cobblestone', 'stones')\n",
    "\n",
    "# Cannot use Python set operations as we require indices and sorting\n",
    "dUnion, iUtr, iUte = union(dTr, dTe)\n",
    "dDiff, iDte = difference(dTe, dTr)\n",
    "dXsect, iXtr, iXte = intersection( dTr, dTe )\n",
    "\n",
    "VoU = initVo(wordvecs, dUnion)\n",
    "VoD = initVo(wordvecs, dDiff)\n",
    "\n",
    "print '----------------------------------'\n",
    "print 'Union:{}, Xsect:{}, dTe-dTr:{}'.format(len(dUnion),len(dXsect),len(dDiff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# sess = tf.InteractiveSession(config=config)\n",
    "graph = tf.Graph().as_default()\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize Vo to word vectors or randomly\n",
    "Vo = initVo(wordvecs, dTr)\n",
    "    \n",
    "# Use sum model or cross-entropy model\n",
    "inputs,pvecs,nvecs,wvecs,wcorr,preds,imloss,wdloss,loss,opt,lrate = imageWmodel(hidden_units=hidden_units, \n",
    "                                                                                vec_size=Vo.shape[1])\n",
    "\n",
    "# Tensorflow Initialization\n",
    "init_op = tf.initialize_all_variables()\n",
    "saver = tf.train.Saver()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update $V_o$\n",
    "\n",
    "Both functions take in:\n",
    "- The input batch vectors ($v_{in}$: `vin`)\n",
    "- The positive vectors ($V_p$: `pVecs`)\n",
    "- The negative vectors ($V_n$: `nVecs`)\n",
    "- The indices in $V_o$ of the positive vectors ($V_p[i]$: `vpindex`)\n",
    "- The indices in $V_o$ of the negative vectors ($V_n[i]$: `vnindex`)\n",
    "- The output vectors $V_o$, `Vo`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lossvals = []\n",
    "losstrain = []\n",
    "lossvalid = []\n",
    "\n",
    "# Consistent validation batches\n",
    "valididx = np.random.choice(range(len(yVa)), size=1024, replace=False, p=None)\n",
    "\n",
    "\n",
    "Cmat = sigmoid(Vo.dot(VoD.T))\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    randidx = np.random.permutation(len(yTr))\n",
    "    yTrr = yTr[randidx]\n",
    "    xTrr = xTr[randidx]\n",
    "    \n",
    "    for b in range(0,len(yTr),bsize):\n",
    "        \n",
    "        # Get a batch\n",
    "        xBatch = xTrr[b:b+bsize]\n",
    "        pVecs, nVecs, vpindex, vnindex = get_batch( yTrr[b:b+bsize], Vo, [5,5] )\n",
    "                \n",
    "        # Run the image updates\n",
    "        _, lossval, vin = sess.run([opt,loss,preds], \n",
    "                                   feed_dict={inputs:xBatch, pvecs: pVecs, \n",
    "                                              nvecs: nVecs, lrate:learnrate,\n",
    "                                              wvecs: VoD, wcorr: Cmat[vpindex].transpose(1,0,2)})\n",
    "        \n",
    "        # Run the word updates\n",
    "        lossvals += [lossval]\n",
    "        if updateVo == 'updateVoX':\n",
    "            Vo = updateVoX(vin, pVecs, nVecs, vpindex, vnindex, Vo, learnrate=learnrate)\n",
    "            VoU = np.array(list(Vo)+list(VoD))\n",
    "            Cmat = sigmoid(VoD.dot(VoU.T))\n",
    "            VoD = adaptWords( VoD, np.array( list(Vo)+list(VoD) ), Cmat, wordlr=learnrate )\n",
    "            Cmat = sigmoid(Vo.dot(VoD.T))\n",
    "            \n",
    "        # Printout status\n",
    "        sys.stdout.write(\"\\rEpoch {}/{}: loss={}\".format(epoch, epochs, lossval))\n",
    "            \n",
    "    # Validation\n",
    "    pVecs, nVecs, vpindex, vnindex = get_batch( yVa[valididx], Vo, [5,5] )\n",
    "    vapred, valossval = sess.run([preds,imloss], feed_dict={inputs:xVa[valididx], pvecs: pVecs, nvecs: nVecs})\n",
    "    yHat = sigmoid(vapred.dot(Vo.T))\n",
    "    precision,recall,f1score = Evaluation( yVa[valididx], yHat, 5).evaluate()\n",
    "    outstring = '\\rEpoch: {}, LR: {}, Train/Val: {}/{}, P: {}, R: {}\\n'.format(epoch,learnrate,lossval,\n",
    "                                                                               lossval,precision,recall)\n",
    "    sys.stdout.write(outstring)\n",
    "    \n",
    "    # Keep track of training and validation loss\n",
    "    losstrain += [lossval]\n",
    "    lossvalid += [valossval]\n",
    "    \n",
    "    # Learning rate updating\n",
    "    if len(losstrain) and len(losstrain) % 150 == 0:\n",
    "        learnrate*=0.9\n",
    "        if learnrate < minlearnrate:\n",
    "            learnrate=minlearnrate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Word Vector Tuning\n",
    "\n",
    "### Given the image vectors, tune the word vectors to match based on original word vector correlation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either run nonlinear or linear (below).\n",
    "\n",
    "#### Nonlinear optimization\n",
    "\n",
    "Nonlinear optimization has a cost function of:\n",
    "\n",
    "$$\\mathcal{L} = \\frac{1}{N} C_{i,o} \\log \\sigma ( V_i^T V_o ) + (1 - C_{i,o}) \\log \\sigma (V_i^T V_o )$$\n",
    "\n",
    "Here, $C_{i,o}$ is the *original* correlation between word *i* and word *o*. We may wish to adapt the nonlinearity that Kyle uses as the final layer for the sum of word vectors. \n",
    "\n",
    "Let $V_{oD}$ be the output vectors of the set difference between training and testing. Since we're in numpy, the updates to maximize are:\n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}^+}{ \\partial V_{oD} } = C \\left( 1 - \\sigma\\left( V_{oD} V_{oU} \\right) \\right) \\cdot V_{oU}$$  \n",
    "\n",
    "$$\\frac{\\partial \\mathcal{L}^-}{ \\partial V_{oD} } = (C - 1) \\left( 1 - \\sigma\\left( 1 - V_{oD} V_{oU} \\right) \\right) \\cdot V_{oU}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear optimization\n",
    "\n",
    "Linear matrix optimization is done here:\n",
    "\n",
    "Let $V_{oD}$ be the set difference output vectors between training set and testing set. That is, the vectors that have *not* been updated in the image optimization. We know that the semantic concepts are correlated with the original correlation matrix $C_m$, and at minimum, an unseen word $v_i$ is correlated with an optimized word from the image training corpus $v_o$ with linear correlation $c_{i,o}$, the $(i, j)^{th}$ entry in $C_m$. \n",
    "\n",
    "Similarly, in the absence of any image data, we know that the vectors are also correlated with each other with that same correlation. If we only optimize the unseen word vectors, then with $V_{oU}$ being the union of the *original* vectors of image labels (before image optimization) and words not in the image label set, then:\n",
    "\n",
    "$$C_m = V_{oD} \\cdot V_{oU}$$\n",
    "\n",
    "With $\\hat{V}_{oU}$ being the union of the *updated* vectors of image labels (after image optimization) and words not in the image label set, the solution to the inverse problem is then:\n",
    "\n",
    "$$\\hat{V}_{oD} = C_m \\hat{V}_{oU} \\left( \\hat{V}_{oU}^T \\hat{V}_{oU} \\right)^{-1} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VoD = initVo(wordvecs, dDiff)\n",
    "VoU = initVo(wordvecs, dUnion)\n",
    "\n",
    "# word parameter optimization\n",
    "wordlr = 1.0e-4\n",
    "nonlinear = False\n",
    "\n",
    "if nonlinear:\n",
    "    Cmat = sigmoid( VoD.dot(VoU.T) )\n",
    "    VoUnew = np.array( list(Vo)+list(VoD) )\n",
    "    # New full vectors. Assumes that Vo is optimized through the image space\n",
    "    for epoch in range(epochs):\n",
    "        VoD = adaptWords( VoD, VoUnew, Cmat, wordlr=wordlr)\n",
    "        sys.stdout.write('\\r{}, Word Adaptation Cost = {}'.format(epoch, costYViVo(Cmat, VoD, VoUnew)))\n",
    "    VoDnew = VoD\n",
    "else:\n",
    "    # Linear optimization\n",
    "    Cmat = 0.3*VoD.dot(VoU.T)\n",
    "    VoUnew = np.array( list(Vo)+list(VoD) )\n",
    "    VoDnew = Cmat.dot(VoUnew).dot(np.linalg.inv(VoUnew.T.dot(VoUnew)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign new $V_{oD}^{new}$ to optimized value for set difference $V_{oD}$.\n",
    "\n",
    "$V_{o Te}= V_{o Tr} ( D[ Tr\\cap Te ] ) \\cup V_{o Te} (  D[Te]-D[Tr]  )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newVo = np.zeros((len(dTe),200))\n",
    "newVo[iXte] = Vo[iXtr]\n",
    "newVo[iDte] = VoD\n",
    "newVo[iDte] = wweight*VoDnew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getsplit(splitname):\n",
    "    # Returns data, labels, output vectors, image list, directory of images, and dictionary\n",
    "    if splitname=='train':\n",
    "        return xTr, yTr, Vo, trainlist, dirTr, dTr\n",
    "    elif splitname=='valid':\n",
    "        return xVa, yVa, Vo, validlist, dirVal, dTr\n",
    "    else:\n",
    "        return xTe, yTe, newVo, testlist, dirTe, dTe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "splitname='test'\n",
    "xEv, yEv, VE, evallist, dirEv, dEv = getsplit(splitname)\n",
    "\n",
    "plt.plot(np.array(losstrain))\n",
    "plt.plot(np.array(lossvalid),'r')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.title('Epoch = {}'.format(epoch))\n",
    "prediction = sess.run(preds, feed_dict={inputs:xEv})\n",
    "yHat = sigmoid(prediction.dot(VE.T))\n",
    "\n",
    "evaluated = Evaluation(yEv, yHat, k=5)\n",
    "evaluated.evaluate()\n",
    "\n",
    "from oct2py import octave\n",
    "octave.addpath('../../evaluation/')\n",
    "[precision, recall, f1score] = octave.evaluate(yEv.T, yHat.T, 5)\n",
    "print \"P: {},R: {},F1: {}\".format(precision,recall,f1score)\n",
    "\n",
    "print 2*(precision*recall) / (precision+recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelname='save-name.model'\n",
    "\n",
    "save_path = saver.save(sess, modelname)\n",
    "\n",
    "print \"Saved model to {}\".format(save_path)\n",
    "\n",
    "modelinfo = modelname+'.info.npz'\n",
    "np.savez( modelinfo, lossvals=lossvals, epoch=epoch, Vo=Vo)\n",
    "\n",
    "print \"Saved model information to {}\".format(modelinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
