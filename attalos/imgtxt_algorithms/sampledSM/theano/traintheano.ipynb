{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano version of positive/negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "os.environ[\"THEANO_FLAGS\"] = \"mode=FAST_RUN,device=gpu0,floatX=float32\"\n",
    "\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import negsamp\n",
    "import matplotlib.pylab as plt\n",
    "from progressbar import ProgressBar as progressbar \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "m = 45               # number of negative samples\n",
    "f = 4096\n",
    "hidden1 = 200\n",
    "hidden2 = 200\n",
    "d = 200              # word vector size\n",
    "V = 291\n",
    "wdecay = 0.01        # weight decay\n",
    "\n",
    "numlayers = 3\n",
    "lr = 100\n",
    "epochs = 10000\n",
    "batchsize=256\n",
    "weightfile = None # 'params-2x_0609.npz'\n",
    "saveparams = 'params-2x_0704.npz'\n",
    "pretrain = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mdata/iaprtc_alexfc7.npz\u001b[0m*     \u001b[01;32mdata/iaprtc_testlist.txt\u001b[0m*\r\n",
      "\u001b[01;32mdata/iaprtc_dictionary.txt\u001b[0m*  \u001b[01;32mdata/iaprtc_trainlist.txt\u001b[0m*\r\n",
      "\r\n",
      "data/wiki-glove:\r\n",
      "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\r\n",
      "glove.6B.200d.txt  glove.6B.50d.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls data/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ingestion. Currently just read in numpy files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.load('data/iaprtc_alexfc7.npz')\n",
    "D = open('data/iaprtc_dictionary.txt').read().splitlines()\n",
    "train_ims = [ im.split('/')[-1] for im in open('data/iaprtc_trainlist.txt').read().splitlines() ]\n",
    "test_ims = [ im.split('/')[-1] for im in open('data/iaprtc_testlist.txt').read().splitlines() ]\n",
    "xTr = data['xTr'].T\n",
    "yTr = data['yTr'].T\n",
    "xTe = data['xTe'].T\n",
    "yTe = data['yTe'].T\n",
    "wc = yTr.sum(axis=0)+0.01-0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in parameters/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized higher-order layers to (200, 4096), (200, 200)\n",
      "Initialized Wi, and Wc shapes: (200, 4096),(200, 200),(291, 200)\n"
     ]
    }
   ],
   "source": [
    "if weightfile and pretrain:\n",
    "    Wi = theano.shared(np.load(weightfile)['Wi'])\n",
    "    if numlayers >= 2:\n",
    "        Wh2 = theano.shared(np.random.ranf((hidden1, f)))\n",
    "    elif numlayers >= 3:\n",
    "        Wh3 = theano.shared(np.random.ranf((hidden2, hidden1)))\n",
    "    Wc = theano.shared(np.load(weightfile)['Wc'])\n",
    "elif weightfile:\n",
    "    Wi = theano.shared(np.load(weightfile)['Wi'])\n",
    "    if numlayers >= 2:\n",
    "        Wh2 = theano.shared(np.load(weightfile)['Wh2'])\n",
    "    if numlayers >= 3:\n",
    "        Wh3 = theano.shared(np.load(weightfile)['Wh3'])\n",
    "    Wc = theano.shared(np.load(weightfile)['Wc'])\n",
    "    progloss = np.load(weightfile)['Losses']\n",
    "else:\n",
    "    # Need to change these to normal distributed\n",
    "    if numlayers == 2:\n",
    "        Wh2 = theano.shared(0.01*(np.random.ranf((hidden1, f))-0.5) )\n",
    "        Wi = theano.shared(0.01*(np.random.ranf((d, hidden1))-0.5) )\n",
    "    if numlayers == 3:\n",
    "        Wh2 = theano.shared(0.01*(np.random.ranf((hidden1, f))-0.5) )\n",
    "        Wh3 = theano.shared(0.01*(np.random.ranf((hidden2, hidden1))-0.5) )\n",
    "        Wi = theano.shared(0.01*(np.random.ranf((d, hidden2))-0.5) )\n",
    "        print \"Initialized higher-order layers to {}, {}\".format(Wh2.get_value().shape, Wh3.get_value().shape)\n",
    "    Wc = theano.shared(0.01*(np.random.ranf((V, d))-0.5) )\n",
    "    progloss= np.array([])\n",
    "    print \"Initialized Wi, and Wc shapes: {},{},{}\".format(Wh2.get_value().shape,Wi.get_value().shape,Wc.get_value().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper and utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def showdata( Wcn, minblk=True, thetitle=None, colorbar=False, blackwhite=False ):\n",
    "    if minblk:\n",
    "        Wcmind1 = np.array(Wcn.shape).min()\n",
    "        Wcmind2 = np.array(Wcn.shape).min()\n",
    "    else:\n",
    "        Wcmind1 = Wcn.shape[0]\n",
    "        Wcmind2 = Wcn.shape[1]\n",
    "    plt.figure\n",
    "    if blackwhite:\n",
    "        print '%d, %d'%(Wcmind1,Wcmind2)\n",
    "        plt.imshow(Wcn[:Wcmind1,:Wcmind2], cmap='Greys_r', interpolation='nearest')\n",
    "    else:\n",
    "        plt.imshow(Wcn[:Wcmind1,:Wcmind2]);\n",
    "    if thetitle:\n",
    "        plt.title(thetitle)\n",
    "    if colorbar:\n",
    "        plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# Define the sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define rectified linear unit (relu)\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathy Part\n",
    "\n",
    "### Cost Function:\n",
    "1. One Layer: $$ y_p = \\sigma(W_c W_i x^T) $$\n",
    "2. Two Layers: $$ y_p = \\sigma( W_c W_i \\sigma( W_h x^T )) $$\n",
    "\n",
    "We are doing SGD only (no momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Negative sampler\n",
    "ns = negsamp.NegativeSampler(wc / wc.sum())\n",
    "\n",
    "# Define functionality\n",
    "x = T.matrix()\n",
    "p = T.matrix()\n",
    "n = T.matrix()\n",
    "\n",
    "# Cross correlation\n",
    "if numlayers==1:\n",
    "    xcorr = Wc.dot(Wi.dot(x.T)).T\n",
    "elif numlayers==2:\n",
    "    # xcorr = Wc.dot(Wi.dot(T.nnet.sigmoid(Wh2.dot(x.T)))).T\n",
    "    xcorr = Wc.dot(Wi.dot(T.nnet.relu(Wh2.dot(x.T)))).T\n",
    "elif numlayers==3:\n",
    "    xcorr = Wc.dot(Wi.dot(T.nnet.relu(Wh3.dot(T.nnet.relu(Wh2.dot(x.T)))))).T\n",
    "\n",
    "# LOSS FUNCTION\n",
    "# Because p and n are {-1,0,1}, these two are the same\n",
    "# loss = -(T.log(T.nnet.sigmoid(p*xcorr)) + T.log(T.nnet.sigmoid(-n*xcorr))).mean()\n",
    "# loss = -T.log(T.nnet.sigmoid( (p-n).dot(xcorr)  )).mean()\n",
    "# loss = (-p * T.log(T.nnet.sigmoid(xcorr)) + n * T.log(T.nnet.sigmoid(xcorr))).mean()\n",
    "loss = -(p*T.log(T.nnet.sigmoid(xcorr)) + n*T.log(T.nnet.sigmoid(-xcorr))).mean()\n",
    "# \n",
    "# Cross-entropy\n",
    "# loss = (n-p)*( T.log( T.nnet.sigmoid(xcorr) ) ).mean()\n",
    "#\n",
    "# Binary cross-entropy\n",
    "# loss = -(p*(T.log( T.nnet.sigmoid(xcorr))) + (1-p)*(T.log( 1-T.nnet.sigmoid(xcorr) ))).mean()\n",
    "\n",
    "# Define the gradient updates. Use positive for maximization\n",
    "if numlayers==1:\n",
    "    params = [Wi, Wc]\n",
    "    gWi, gWc = T.grad(loss, params)\n",
    "    sgd = OrderedDict( { Wi: Wi - lr*gWi, Wc: Wc - lr*gWc } )\n",
    "elif numlayers==2:\n",
    "    params = [Wi, Wc, Wh2]\n",
    "    gWi, gWc, gWh2 = T.grad(loss, params)\n",
    "    sgd = OrderedDict( { Wi: Wi - lr*gWi, Wc: Wc - lr*gWc, Wh2: Wh2 - lr*gWh2 } )\n",
    "elif numlayers==3:\n",
    "    params = [Wi, Wc, Wh2, Wh3]\n",
    "    gWi, gWc, gWh2, gWh3 = T.grad(loss, params)\n",
    "    sgd = OrderedDict( { Wi: Wi - lr*gWi, Wc: Wc - lr*gWc, Wh2: Wh2 - lr*gWh2, Wh3: Wh3 - lr*gWh3 } )\n",
    "\n",
    "# Compile to theano functionality\n",
    "train = theano.function( [x,p,n], outputs=loss, updates=sgd, allow_input_downcast=True )\n",
    "predict= theano.function( [x], outputs=xcorr, allow_input_downcast=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do SGD on the cost function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*****************93%***************   ]  16385 of 17665 complete \n",
      "losses (inst, bat, tot)=(0.0962084118206,1.54684331141,1.54684331141)\n"
     ]
    }
   ],
   "source": [
    "progbar = progressbar(len(yTr))\n",
    "\n",
    "# Iterate through the data size\n",
    "for j in xrange(epochs):\n",
    "    print \"Epoch \"+str(j)\n",
    "    k=0\n",
    "    totloss = 0.0\n",
    "    batloss = 0.0\n",
    "    randorder = np.random.permutation(len(yTr))\n",
    "    for i in range(0,len(randorder),batchsize):\n",
    "        \n",
    "        indata = xTr[i:i+batchsize]\n",
    "        outdata= yTr[i:i+batchsize]\n",
    "\n",
    "        nsv = ns.negsampv(outdata, m)\n",
    "        lossval = train( indata, outdata, nsv )\n",
    "        totloss += lossval\n",
    "        batloss += lossval\n",
    "\n",
    "        k+=1\n",
    "        if k % 16 == 0:\n",
    "            # Progress and loss\n",
    "            progbar.animate(k*batchsize)\n",
    "            print('\\nlosses (inst, bat, tot)=({},{},{})'.format(lossval, batloss, totloss))\n",
    "            \n",
    "    print \"\"\n",
    "    print \"Total loss on epoch \"+str(j)+\" = \"+str(totloss)+\"\\n\"\n",
    "    progloss = np.append(progloss, totloss)\n",
    "    print \"Progress: {}\".format( progloss )\n",
    "    plt.plot(progloss)\n",
    "\n",
    "    \n",
    "    if numlayers==1:\n",
    "        np.savez(saveparams, Wi=Wi.get_value(), Wc=Wc.get_value(), Epoch=j, Losses=progloss)      \n",
    "    elif numlayers==2:\n",
    "        np.savez(saveparams, Wi=Wi.get_value(), Wh2=Wh2.get_value(), Wc=Wc.get_value(), Epoch=j, Losses=progloss)      \n",
    "    elif numlayers==3:\n",
    "        np.savez(saveparams, Wi=Wi.get_value(), Wh2=Wh2.get_value(), Wh3=Wh3.get_value(), Wc=Wc.get_value(), Epoch=j, Losses=progloss)      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the arrays to parameter files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if numlayers==1:\n",
    "    np.savez(saveparams, Wi=Wi.get_value(), Wc=Wc.get_value(), Epoch=j)      \n",
    "elif numlayers==2:\n",
    "    np.savez(saveparams, Wi=Wi.get_value(), Wh2=Wh2.get_value(), Wc=Wc.get_value(), Epoch=j, Losses=progloss)      \n",
    "elif numlayers==3:\n",
    "    np.savez(saveparams, Wi=Wi.get_value(), Wh2=Wh2.get_value(), Wh3=Wh3.get_value(), Wc=Wc.get_value(), Epoch=j, Losses=progloss)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy verification and debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get arrays from GPU, and make sample inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 140.92060172    7.62086023    6.96315359 ...,    6.95386771    6.96357229\n",
      "    6.95951553]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2bf33599d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get parameters from the GPU arrays\n",
    "Ws = []\n",
    "if numlayers >= 3:\n",
    "    Ws.append( Wh3.get_value() )\n",
    "if numlayers >= 2:\n",
    "    Ws.append( Wh2.get_value() )\n",
    "Win  = Wi.get_value()\n",
    "Wout = Wc.get_value()\n",
    "# plt.stem(W0.dot(xTe[40]))\n",
    "\n",
    "xD = xTe[:256]\n",
    "yD = yTe[:256]\n",
    "npp = yD\n",
    "npn = ns.negsampv(yD, m)\n",
    "\n",
    "plt.plot(progloss)\n",
    "print progloss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
