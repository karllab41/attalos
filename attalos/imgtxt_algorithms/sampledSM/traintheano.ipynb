{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano version of positive/negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import theano.tensor as T\n",
    "import theano\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import negsamp\n",
    "import matplotlib.pylab as plt\n",
    "from progressbar import ProgressBar as progressbar \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Params\n",
    "d = 100\n",
    "f = 4096\n",
    "hidden = 4096\n",
    "V = 291\n",
    "m=25\n",
    "\n",
    "numlayers = 2\n",
    "lr = 0.01\n",
    "epochs = 100\n",
    "batchsize=256\n",
    "weightfile = None # 'params-2layer.npz'\n",
    "pretrain = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ingestion. Currently just read in numpy files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.load('../data/iaprtc_alexfc7.npz')\n",
    "D = open('../data/iaprtc_dictionary.txt').read().splitlines()\n",
    "train_ims = [ im.split('/')[-1] for im in open('../data/iaprtc_trainlist.txt').read().splitlines() ]\n",
    "test_ims = [ im.split('/')[-1] for im in open('../data/iaprtc_testlist.txt').read().splitlines() ]\n",
    "xTr = data['xTr'].T\n",
    "yTr = data['yTr'].T\n",
    "xTe = data['xTe'].T\n",
    "yTe = data['yTe'].T\n",
    "wc = yTr.sum(axis=0)+0.01-0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in parameters/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Wh, Wi, and Wc shapes: \n",
      "(4096, 4096)\n",
      "(100, 4096)\n",
      "(291, 100)\n"
     ]
    }
   ],
   "source": [
    "if weightfile and pretrain:\n",
    "    Wi = theano.shared(np.load(weightfile)['Wi'])\n",
    "    Wh = theano.shared(np.random.ranf((hidden, f)))\n",
    "    Wc = theano.shared(np.load(weightfile)['Wc'])\n",
    "elif weightfile:\n",
    "    Wi = theano.shared(np.load(weightfile)['Wi'])\n",
    "    Wh = theano.shared(np.load(weightfile)['Wh'])\n",
    "    Wc = theano.shared(np.load(weightfile)['Wc'])\n",
    "else:\n",
    "    # Need to change these to normal distributed\n",
    "    Wh = theano.shared(np.random.ranf((hidden, f))-0.5)\n",
    "    Wi = theano.shared(np.random.ranf((d, hidden))-0.5)\n",
    "    Wc = theano.shared(np.random.ranf((V, d))-0.5)\n",
    "    \n",
    "    print \"Initialized Wh, Wi, and Wc shapes: {},{},{}\".format(Wh.get_value().shape,Wi.get_value().shape,Wc.get_value().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper and utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def showdata( Wcn, minblk=True, thetitle=None, colorbar=False, blackwhite=False ):\n",
    "    if minblk:\n",
    "        Wcmind1 = np.array(Wcn.shape).min()\n",
    "        Wcmind2 = np.array(Wcn.shape).min()\n",
    "    else:\n",
    "        Wcmind1 = Wcn.shape[0]\n",
    "        Wcmind2 = Wcn.shape[1]\n",
    "    plt.figure\n",
    "    if blackwhite:\n",
    "        print '%d, %d'%(Wcmind1,Wcmind2)\n",
    "        plt.imshow(Wcn[:Wcmind1,:Wcmind2], cmap='Greys_r', interpolation='nearest')\n",
    "    else:\n",
    "        plt.imshow(Wcn[:Wcmind1,:Wcmind2]);\n",
    "    if thetitle:\n",
    "        plt.title(thetitle)\n",
    "    if colorbar:\n",
    "        plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# Define the sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Define rectified linear unit (relu)\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathy Part\n",
    "\n",
    "### Cost Function:\n",
    "1. One Layer: $$ y_p = \\sigma(W_c W_i x^T) $$\n",
    "2. Two Layers: $$ y_p = \\sigma( W_c W_i \\sigma( W_h x^T )) $$\n",
    "\n",
    "We are doing SGD only (no momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Negative sampler\n",
    "ns = negsamp.NegativeSampler(wc / wc.sum())\n",
    "\n",
    "# Define functionality\n",
    "x = T.matrix()\n",
    "p = T.matrix()\n",
    "n = T.matrix()\n",
    "\n",
    "# Cross correlation\n",
    "if numlayers==1:\n",
    "    xcorr = Wc.dot(Wi.dot(x.T)).T\n",
    "else:\n",
    "    # xcorr = Wc.dot(Wi.dot(T.nnet.sigmoid(Wh.dot(x.T)))).T\n",
    "    xcorr = Wc.dot(Wi.dot(T.nnet.relu(Wh.dot(x.T)))).T\n",
    "\n",
    "# LOSS FUNCTION\n",
    "# Because p and n are {-1,0,1}, these two are the same\n",
    "# loss = -(T.log(T.nnet.sigmoid(p*xcorr)) + T.log(T.nnet.sigmoid(-n*xcorr))).mean()\n",
    "# loss = -T.log(T.nnet.sigmoid( (p-n).dot(xcorr)  )).mean()\n",
    "# loss = (-p * T.log(T.nnet.sigmoid(xcorr)) + n * T.log(T.nnet.sigmoid(xcorr))).mean()\n",
    "loss = -(p*T.log(T.nnet.sigmoid(xcorr)) + n*T.log(T.nnet.sigmoid(-xcorr))).mean()\n",
    "# \n",
    "# Cross-entropy\n",
    "# loss = (n-p)*( T.log( T.nnet.sigmoid(xcorr) ) ).mean()\n",
    "#\n",
    "# Binary cross-entropy\n",
    "# loss = -(p*(T.log( T.nnet.sigmoid(xcorr))) + (1-p)*(T.log( 1-T.nnet.sigmoid(xcorr) ))).mean()\n",
    "\n",
    "# Define the gradient updates. Use positive for maximization\n",
    "if numlayers==1:\n",
    "    params = [Wi, Wc]\n",
    "    gWi, gWc = T.grad(loss, params)\n",
    "    sgd = OrderedDict( { Wi: Wi - lr*gWi, Wc: Wc - lr*gWc } )\n",
    "else:\n",
    "    params = [Wi, Wc, Wh]\n",
    "    gWi, gWc, gWh = T.grad(loss, params)\n",
    "    sgd = OrderedDict( { Wi: Wi - lr*gWi, Wc: Wc - lr*gWc, Wh: Wh - lr*gWh } )\n",
    "\n",
    "# Compile to theano functionality\n",
    "train = theano.function( [x,p,n], outputs=loss, updates=sgd, allow_input_downcast=True )\n",
    "predict= theano.function( [x], outputs=xcorr, allow_input_downcast=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do SGD on the cost function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                  0%                  ] \n",
      "losses (inst, bat, tot)=(2.39360935084,41.193562883,41.193562883)\n"
     ]
    }
   ],
   "source": [
    "progbar = progressbar(len(yTr))\n",
    "# progloss= []\n",
    "\n",
    "# Iterate through the data size\n",
    "for j in xrange(epochs):\n",
    "    print \"Epoch \"+str(j)\n",
    "    k=0\n",
    "    totloss = 0.0\n",
    "    batloss = 0.0\n",
    "    randorder = np.random.permutation(len(yTr))\n",
    "    for i in range(0,len(randorder),batchsize):\n",
    "        \n",
    "        indata = xTr[i:i+batchsize]\n",
    "        outdata= yTr[i:i+batchsize]\n",
    "\n",
    "        nsv = ns.negsampv(outdata, m)\n",
    "        lossval = train( indata, outdata, nsv )\n",
    "        totloss += lossval\n",
    "        batloss += lossval\n",
    "\n",
    "        k+=1\n",
    "        if k % 16 == 0:\n",
    "            # Progress and loss\n",
    "            progbar.animate(k*batchsize)\n",
    "            print('\\nlosses (inst, bat, tot)=({},{},{})'.format(lossval, batloss, totloss))\n",
    "            \n",
    "    print \"\"\n",
    "    print \"Total loss on epoch \"+str(j)+\" = \"+str(totloss)+\"\\n\"\n",
    "    progloss.append(totloss)\n",
    "    print \"Progress: {}\".format( progloss )\n",
    "    \n",
    "    if numlayers==1:\n",
    "        np.savez('params-ix.npz', Wi=Wi.get_value(), Wc=Wc.get_value(), Epoch=j)      \n",
    "    else:\n",
    "        np.savez('params-ix.npz', Wi=Wi.get_value(), Wh=Wh.get_value(), Wc=Wc.get_value(), Epoch=j)      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the arrays to parameter files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if numlayers==1:\n",
    "    np.savez('params-ix.npz', Wi=Wi.get_value(), Wc=Wc.get_value(), Epoch=j)      \n",
    "else:\n",
    "    np.savez('params-ix.npz', Wi=Wi.get_value(), Wh=Wh.get_value(), Wc=Wc.get_value(), Epoch=j)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy verification and debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get arrays from GPU, and make sample inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get parameters from the GPU arrays\n",
    "W0 = Wh.get_value()\n",
    "W1 = Wi.get_value()\n",
    "W2 = Wc.get_value()\n",
    "# plt.stem(W0.dot(xTe[40]))\n",
    "\n",
    "xD = xTe[:256]\n",
    "yD = yTe[:256]\n",
    "npp = yD\n",
    "npn = ns.negsampv(yD, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functionality to check the shapes of current arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numlayers=2\n",
    "if numlayers==1:\n",
    "    npxcorr = W2.dot(W1.dot(xD.T))\n",
    "else:\n",
    "    npxcorr = W2.dot(W1.dot(sigmoid(W0.dot(xD.T))))\n",
    "\n",
    "print 'Shapes, p:'+str(npp.shape)+', n:'+str(npn.shape)+', xcorr:'+str(npxcorr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h1 = W1.dot(xD.T)\n",
    "plt.stem(h1[1]); plt.figure()\n",
    "plt.stem(h1[2]); plt.figure()\n",
    "plt.stem(h1[3]); plt.figure()\n",
    "plt.imshow(W1[:,:300]); plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "npxcorr.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
